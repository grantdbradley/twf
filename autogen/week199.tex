
% </A>
% </A>
% </A>
\week{December 8, 2003 }



I've had a really busy quarter, teaching 3 courses that all require
serious thought on my part, so it's been a long while since I've been
able to write an issue of This Week's Finds.  But, back in September 
I went to a conference on homotopy theory and its applications at the
University of Western Ontario, run by Dan Christensen and Rick
Jardine.  There were some really cool talks at this conference - my
favorite was one by Jack Morava about elliptic cohomology, and I'm
really sorry I missed his lectures on Galois theory, since I've been
studying that lately.  But, instead of trying to describe the talks, 
I think it would be better if I said a bit about "spectra", 
which are an important tool in homotopy theory.

The word "spectrum" has a lot of different meanings in mathematics 
and physics.  In experimental physics it refers to the frequencies of
light, sound or any other sort of wave emitted by an object.  For
example, if you send the light emitted by hydrogen through a
spectrometer, you'll see a bunch of sharp lines at specific
frequencies - the "discrete" spectrum" - along with a diffuse glow at
all frequencies - the "continuous spectrum".  The German high school
teacher Balmer noticed that the sharp lines correspond to light with
frequencies proportional to


$$

1/n^{2} - 1/m^{2}
$$
    
where n,m = 1,2,3,...  

These days, in theoretical physics the "spectrum" of something is the
set of frequencies at which it can vibrate - or in quantum theory, the
set of energies it can have, since an energy is just a frequency times
Planck's constant.  For example, Bohr took Balmer's formula and
realized that a hydrogen atom must have a discrete set of allowed
energy levels


$$

-1/n^{2}
$$
    

When the atom hops from one energy level to another, it emits or
absorbs light with energy equal to the difference of two such numbers!
This accounts for the discrete spectrum of light emitted by hydrogen.
The atom can also have any \emph{positive} energy, and this accounts for
the continuous spectrum.

In quantum mechanics, observables like energy are described as
self-adjoint operators on a Hilbert space.  The "spectrum" of an
observable A is the set of values it's allowed to have, and
mathematically this is the set of numbers x such that the operator A - x 
has no inverse.  For example, if A is a "Hamiltonian", the operator
that describes the energy of a quantum system, its spectrum is just
the set of allowed energies!  The simplest case is when x is an
eigenvalue of A: the eigenvalues of an operator form its "discrete
spectrum".  But, there can also be numbers in the spectrum that aren't
eigenvalues, and these form the "continuous spectrum".

In mathematical physics, people talk about the spectrum not just
of one observable but of a whole bunch of commuting observables, since
commuting observables can be measured simultaneously without the Heisenberg
uncertainty principle kicking in to limit the precision.   The nice way to 
think of the spectrum of a bunch of operators uses the concept of 
"C*-algebra".  If we've got a bunch of bounded operators on a Hilbert 
space that's closed under addition, multiplication and scalar 
multiplication, closed under taking adjoints and also closed in the 
norm topology, it's called a "C*-algebra".   The "spectrum" of a 
C*-algebra A is the set of all homomorphisms 


$$

x: A \to  C, 
$$
    
where C is the complex numbers.  Though it's not immediately obvious,
this sort of spectrum reduces to the previous one when A is the
C*-algebra of operators generated by a single self-adjoint operator.
So, it's a nice way to define the spectrum of a whole bunch of
observables.  This generalization is not very useful when the
C*-algebra is noncommutative, since then it may not have many
homomorphisms to the complex numbers.  But if it's commutative, we know
\emph{everything} about it once we know its spectrum!

This amazing fact is called the Gelfand-Naimark theorem.  Here's 
the idea.  There's an easy way to make the spectrum of a commutative
C*-algebra A into a topological space: we say x_{i} \to  x 
precisely when


$$

x_{i}(a) \to  x(a)
$$
    
for all elements a of A.  With this topology any
element a of A gives a continuous complex function on the spectrum, 
defined by this clever formula:

a(x) = x(a).

The physicist Chris Isham says he couldn't sleep all night when he
first saw this formula, it's so darn clever!  And, it turns out that
\emph{any} continuous function on the spectrum comes from an element of A
via this formula!  So, if you hand me the spectrum Spec(A) of a
commutative C*-algebra A, I can recover A (up to isomorphism) by
forming the C*-algebra of all continuous functions on Spec(A).

As you can see, the concept of spectrum is getting more abstract - but
it still has close ties to the original idea.  What once was a bunch
of lines on a spectrometer has now become a topological space
associated to a commuting collection of observables.  The idea is that
each point in this space is a way of assigning values to all these
observables... just like each line in the spectrometer represents a
particular frequency of light!

But the abstraction process doesn't stop here.  In algebraic geometry, 
people want to think of \emph{any} commutative ring as consisting of functions 
on some sort of space.  For example, the commutative ring of real 
polynomials in two variables mod the relation

x^{2} + y^{2} = 1

is just another way of thinking about polynomial functions on the circle.
How do we get the circle back from this commutative ring?  Simple: just 
form the space of all homomorphisms from it to the real numbers! 

It would be nice to have a recipe to take any commutative ring A and
extract a space from it: its "spectrum".  As we've seen, one option is
to take the spectrum to consist of all homomorphisms to the complex
numbers:


$$

x: A \to  C
$$
    

Another would be to use the real numbers:


$$

x: A \to  R.
$$
    

Both the real and complex numbers are "fields": commutative rings
where we can divide by anything nonzero.  But there are a lot of other
fields, like Z/p where p is any prime number.  So, instead of picking
one field, a more evenhanded approach is to use \emph{all possible} fields,
and say a homomorphism to any one of these should give a point of the
spectrum.

Actually, since there are zillions of fields out there, a more
manageable option is to look not at the homomorphism itself but its
kernel: the set of elements a in A with


\begin{verbatim}

x(a) = 0.
\end{verbatim}
    

The kernel of a homomorphism from A to any other ring is an "ideal": a
set closed under addition and also multiplication by all elements of
A.  Even better, the kernel of a homomorphism from A to a \emph{field} is a
"prime" ideal, meaning it's not not all of A, and whenever the product
of two elements of A lies in the ideal, at least one of them must be
in the ideal.  Conversely, given a prime ideal in A, there's always a
field k and a homomorphism


$$

x: A \to  k 
$$
    
whose kernel is that prime ideal.  So, it's reasonable to define 
the spectrum of A, Spec(A) to be the set of all prime ideals in A.  

This turns out to exactly match the previous definition of spectrum when A 
is a C*-algebra.  But why the word "prime"?  Well, in the commutative 
ring of integers, Z, most prime ideals come from prime numbers.  If we 
take all the multiples of any prime number, we get a prime ideal, which 
is the kernel of the obvious homomorphism


$$

x: Z \to  Z/p
$$
    

There's just one other prime ideal in Z, namely all the multiples of
0.  In other words, the set consisting of just 0 alone!  This is the
kernel of the homomorphism from Z into the rationals.  For some
fascinating reason I'd rather not explain now, this prime ideal is
often called "the prime at infinity".  It's different from all the
rest, but the wise know it's usually good to keep it in.

So, the spectrum of the integers is just the set of ordinary primes
together with the "prime at infinity":


$$

Spec(Z) = {2, 3, 5, 7, 11, ... \infty }
$$
    

We seem to have gotten pretty far from physics by now, but in fact many 
people believe that taking this spectrum seriously from a \emph{physical}
viewpoint will be crucial to proving the Riemann hypothesis - a famous 
open conjecture related to the distribution of prime numbers.  I don't 
have time to do justice to this, but the basic idea goes as follows.  

Suppose we have a quantum system whose Hamiltonian has this spectrum:


\begin{verbatim}

{ln 2, ln 3, ln 5, ln 7, ln 11, ....}
\end{verbatim}
    
We can think of these as energy states of some sort of particle: the
"primon".  

Now let's second quantize this system.  The idea of second quantization 
is that we form a new system consisting of an arbitrary finite collection 
of noninteracting indistinguishable copies of the original system.  For 
example, if the original system was some sort of particle, a state of 
the new system would consist of an arbitrary number of particles of 
this sort, treated as identical bosons.  If second quantize our "primon",
we'll get a system with energy levels that are arbitrary sums of entries 
from the above list.  If we write them in increasing order, they look 
like this:


\begin{verbatim}

{0, ln 2, ln 3, ln 2 + ln 2, ln 5, ln 2 + ln 3, ln 7, ln 2 + ln 2 + ln 2, ....}
\end{verbatim}
    
or in other words, just


\begin{verbatim}

{ln 1, ln 2, ln 3, ln 4, ln 5, ln 6, ln 7, ln 8, ....}
\end{verbatim}
    
since every whole number can be built from primons in a unique way!
Bernard Julia calls this new system the "free Riemann gas", since it's made
of noninteracting primons - and in a minute we'll see it's related to the 
Riemann hypothesis.

To see this, let's do some statistical mechanics with the free Riemann gas!  
As usual, at any temperature T the probability that this system will be in a 
state of energy E is proportional to


$$

exp(-\beta E)
$$
    
where \beta  = 1/kT and k is Boltzmann's constant.  But to get these
numbers to add up to one as probabilities should, we have to normalize
them, dividing by their sum, which goes by the name of the "partition
function".  The partition function for the free Riemann gas is:


$$

                           -\beta 
 \sum exp(-\beta  ln n)   =   \sum  n
 n                    n
$$
    

the so-called "Riemann zeta function".  It's well-defined for \beta  > 1 -
that is, low temperatures - but it blows up when \beta  = 1.  This means that 
the free Riemann gas has a "Hagedorn temperature": a temperature that it 
can't go above, because doing so would take an infinite amount of energy.  

Nonetheless we can analytically continue the Riemann zeta function
around \beta  = 1, and the Riemann hypothesis says that it can only
vanish if \beta  is a negative even integer or a number with real part
equal to 1/2.  And, precisely because the free Riemann gas is made of
primons, this hypothesis has a lot to do with prime numbers!  For
example, it's equivalent to the assertion that the number of primes
less than x differs from


$$

          \infty  
Li(x) =  &int;  dt/ln t  
         2
$$
    

by less than some constant times ln(x) \sqrt x.  

All this is lots of fun.  I urge the physicist reader to compute the free 
energy and specific heat of the free Riemann gas, and also to investigate
the system where we treat the primons as fermions.  But, the big question 
is whether we can use physics-inspired reasoning to prove the Riemann 
hypothesis!

In 1995, a step in this direction was taken by Bost and Connes.  I'm
not ready to really explain it, so I'll just tantalize you by dangling
their abstract in front of you:

\begin{quote}
    In this paper, we construct a natural C*-dynamical system whose 
    partition function is the Riemann zeta function.  Our construction 
    is general and associates to an inclusion of rings (under a 
    suitable finiteness assumption) an inclusion of discrete groups 
    (the associated ax + b groups) and the corresponding Hecke algebras 
    of bi-invariant functions.  The latter algebra is endowed with a
    canonical one-parameter group of automorphisms measuring the lack 
    of normality of the subgroup.  The inclusion of rings Z provides 
    the desired C*-dynamical system, which admits the zeta function 
    as partition function and the Galois group Gal(Q^{cycl}/ Q) of 
    the cyclotomic extension Q^{cycl} of Q as symmetry group.  Moreover, 
    it exhibits a phase transition with spontaneous symmetry breaking at 
    inverse temperature \beta  = 1.
\end{quote}

Here's the reference:

1) J.-B. Bost and Alain Connes, "Hecke Algebras, Type III factors and phase 
transitions with spontaneous symmetry breaking in number theory", Selecta 
Math. (New Series), 1 (1995) 411-457. 

The idea of the free Riemann gas was introduced most clearly by Julia, 
though there were many precursors:

2) Bernard L. Julia, Statistical theory of numbers, in Number Theory
and Physics, eds.  J. M. Luck, P. Moussa, and M. Waldschmidt, Springer
Proceedings in Physics, Vol. 47, Springer-Verlag, Berlin, 1990,
pp. 276-293.  Summarized by Matthew Watkins in
<A HREF = "http://www.maths.ex.ac.uk/~mwatkins/zeta/Julia.htm">http://www.maths.ex.ac.uk/~mwatkins/zeta/Julia.htm</A>

Matthew Watkins has a lot of other fascinating material about prime numbers
and physics on his website:

3) Matthew Watkins, <A HREF = "http://www.maths.ex.ac.uk/~mwatkins/">http://www.maths.ex.ac.uk/~mwatkins/</A>

so this is the best place to start if you're a beginner wanting to
learn more about this stuff.  There are also a bunch of new popular
books on the Riemann hypothesis, so if you're looking for good
Christmas gifts, you might try one of these:

4) Marcus du Sautoy, The Music of the Primes: Searching to Solve the Greatest
Mystery in Mathematics, HarperCollins, 2003.

5) Karl Sabbagh, The Riemann Hypothesis: the Greatest Unsolved Problem
in Mathematics, Farrar Strauss \text{\&}  Giroux, 2003.

6) John Derbyshire, Prime Obsession: Bernhard Riemann and the Greatest 
Unsolved Problem Mathematics, Joseph Henry Press, 2003.

I haven't read any of them, but from reviews it sounds like the third
one focuses on Riemann while the first two talk more about modern
developments.

If you want something quite a bit more substantial but still not requiring
a PhD, try this:

7) Jeffrey Stopple, A Primer of Analytic Number Theory: from Pythagoras
to Riemann, Cambridge U. Press, Cambridge, 2003.

This is the only introduction to analytic number theory that's so simple that
I feel I have a good chance of reading it all the way through.

There's also a lot of interesting work relating the Riemann zeta
function to quantum chaos.  Alas, I don't know how this is related to
the "free Riemann gas" idea!  But here's a nice easy introduction:

8) Barry Cipra, A prime case of chaos, in What's Happening in the 
Mathematical Sciences, vol. 4, American Mathematical Society.  Also 
available at <A HREF = "http://www.maths.ex.ac.uk/~mwatkins/zeta/cipra.htm">http://www.maths.ex.ac.uk/~mwatkins/zeta/cipra.htm</A>

Finally, if you get stuck on the fermionic version of the free Riemann
gas, read Julia's paper or this one:

9) Donald Spector, Supersymmetry and the Moebius inversion function,
Communications in Mathematical Physics 127 (1990) 239-252.

Anyway, all this post up to now has been just a big joke - although everything
I said is true.  The joke is that all this stuff about different meanings of 
"spectrum" has nothing to do with the sort of "spectra" they were
talking about at that conference on homotopy theory!  Topologists like to
study a completely different sort of spectrum... so now let me talk about
those.
 
In topology, a "spectrum" is defined to be a sequence of pointed
topological spaces, each of which is homeomorphic to the space of all
based loops in the next.  So, each space in a spectrum is an "infinite
loop space": a space of loops in a space of loops in a space of loops
in....

In "<A HREF = "week149.html">week149</A>" I described how this sort of spectrum gives a generalized
cohomology theory, and I mentioned a bunch of examples. I gave some
more examples in "<A HREF = "week150.html">week150</A>" and "<A HREF = "week197.html">week197</A>".  But I never described the
cool way to construct spectra that Graeme Segal came up with - so let
me do that now.

There's a cute way to get a space from a category that goes like this.
First create a simplicial set from your category, with one 0-simplex for
each object:


\begin{verbatim}

                       .
                       x
\end{verbatim}
    
one 1-simplex for each morphism:


$$

                       f
                .------>------.
                x             y
$$
    
one 2-simplex for each composable pair of morphisms:


$$

                       y
                       .
                      / \
                     /   \
                    /     \
                  f/       \g
                  /         \
                 /           \
                /             \
               /      fg       \
              .------->---------.
              x                 z

$$
    
and so on ad infinitum.  This is called the "nerve" of the category.
Then, think of this simplicial set as a topological space - i.e., take
its "geometric realization".  The result is called the "classifying
space" of the category.  By the way, I described this construction in
a lot more detail in "<A HREF = "week117.html">week117</A>".  I also explained how you can get
\emph{every} space, up to homotopy equivalence, as the classifying space of
some category!  But what I didn't say is this:

If you start with a monoidal category, the group completion of 
its classifying space will be a loop space.  <BR>
You can get any loop space this way.

If you start with a braided monoidal category, the group completion of 
its classifying space will be a double loop space.  <BR>
You can get any double loop space this way.

If you start with a symmetric monoidal category, the group completion of
its classifying space will be an infinite loop space.  <BR>
You can get any infinite loop space this way.

Huh?  There are lots of terms here that I haven't defined yet....

For starters, a "loop space" is the space of based loops in some
pointed topological space.  A "double loop space" is the space of
based loops in the space of based loops in some pointed topological
space, and so on.  Secondly, all the above statements are only true up
to homotopy equivalence.  Third, I'm talking about various sorts of
category here.  A monoidal category is roughly a category with a
tensor product.  This gives its classifying space a product, making it
into a topological monoid; turning this into a group by throwing in
inverses is called "group completion".  A braided monoidal category is
roughly a monoidal category with an isomorphism

B_{x,y}: x \otimes  y \to  y \otimes  x

for any pair of objects; we require this isomorphism satisfy some rules 
motivated by thinking it as a "braiding", like this:


\begin{verbatim}

              x            y
               \          /
                \        /
                 \      /
                  \    /
                   \  /
                     /
                    /
                   /  \
                  /    \
                 /      \
                /        \
               /          \
              y            x
\end{verbatim}
    
A symmetric monoidal category is a braided monoidal category for which
B_{x,y} is the inverse of B_{y,x}.  Some more details
on these category-theoretic notions can be found in "<A HREF =
"week121.html">week121</A>".

Symmetric monoidal categories abound in mathematics, so we can easily use 
them to get lots of nice infinite loop spaces - and thence spectra and 
generalized cohomology theories!

For example, if we take the category of finite sets, with disjoint
union as the "tensor product", and the obvious braiding, 
the group completion of its classifying space will be


$$

\Omega ^{\infty } S^{\infty }  =  lim  \Omega ^{k} S^{k}
         k \to  \infty 
$$
    

the limit of taking the kth loop space of the k-sphere!  The
corresponding spectrum is called the "sphere spectrum" and
the corresponding generalized cohomology theory is called "stable
homotopy theory".

If we take the category of finite-dimensional complex vector spaces,
with direct sum as the "tensor product", and the obvious
braiding, the group completion of its classifying space will be


$$

BU(\infty ) =   lim        BU(k)
              k \to  \infty 
$$
    

where BU(k) is the classifying space of the group of k x k unitary
matrices!  The corresponding spectrum is called the "spectrum for
connective complex K-theory" and the corresponding generalized
cohomology theory is called "connective complex K-theory".  (Here
"connective" refers to the fact that unlike some other K-theory you
may be familiar with, the cohomology groups K^{i} with i negative have
been set to zero.)

More generally, we can take the category of finitely generated
projective modules of a ring R, again
with direct sum as the tensor product and the obvious braiding.  This
gives something called "algebraic K-theory".  More precisely, the 
homotopy 
groups of the resulting infinite loop space are called the algebraic K-theory
groups K_{i}(R).  

Yet another example comes from taking the category of finite CW
complexes, with disjoint union as the "tensor product" and the obvious
braiding.  This gives a generalized cohomology theory called
"A-theory", due to Waldhausen.

I would like to say more about this stuff sometime.  There's a lot more 
to say!  For example, there are some cool relations between the algebraic 
K-theory groups of the integers, K_{i}(Z), and 
the Riemann zeta function at odd integers, \zeta (2n+1).
(Hmm, so maybe the different sort of spectra \emph{are} related!)  There's 
also a lot of nice stuff about how algebraic K-theory is related to topology.
You can learn about that here:

10) Jonathan Rosenberg, K-theory and geometric topology, available at
<A HREF = "http://www.math.umd.edu/users/jmr/geomtop.pdf">
http://www.math.umd.edu/users/jmr/geomtop.pdf</A>

But, I'll stop here for now.  For more on how different sorts of category
can be used to get ahold of n-fold loop spaces, see:

11) C. Balteanu, Z. Fiedorowicz, R. Schwaenzl, and R. Vogt, Iterated monoidal 
categories, available at <A HREF = "http://www.arXiv.org/abs/math.AT/9808082">math.AT/9808082</A>.

\par\noindent\rule{\textwidth}{0.4pt}
\textbf{Addenda:} Here's my reply to some questions, and also some comments
by my friend Squark about my use of the term "the prime at infinity".

 Rene Meyer wrote:
\begin{quote}

$$

 John Baez wrote:

 > The "spectrum" of a C*-algebra A is the set of all homomorphisms
 > x: A \to  C,
 > where C is the complex numbers.  
 >
 > There's an easy way to make the spectrum of a commutative
 > C*-algebra A into a topological space: we say x_{i} \to  x precisely when
 > x_{i}(a) \to  x(a)
 > for all elements a of A.  With this topology any element a of A gives
 > a continuous complex function on the spectrum, defined by this clever
 > formula:

 I don't understand what you mean by
 
 x_{i} \to  x
 x_{i}(a) \to  x(a)
\end{quote}
$$
    
 That's a way of saying that the sequence x_{i} converges to x,
 or the sequence x_{i}(a) converges to x(a).
\begin{quote}

\begin{verbatim}

 What has the index i to do with this?
\end{verbatim}
    
\end{quote}
 It's the index for some sequence of homomorphisms, x_{i}.
\begin{quote}

$$

 x_{i} and x are the above mentioned homomorphisms, right?
\end{quote}
$$
    
 x is a homomorphism, x_{i} is a sequence of homomorphisms,
 and I'm telling you when the sequence x_{i} converges to x.
\begin{quote}

\begin{verbatim}

 Could you explain in a little more detail?
</BLOCKQUOTE>
\end{verbatim}
    
 I was describing how to make the spectrum of a C*-algebra into a 
 topological space.  One way to do this is to say when a sequence
 x_{i} of points in the spectrum converges to some point x.  So, I 
 took a sequence of homomorphisms


$$

 x_{i}: A \to  C
$$
    
 and told you when it converges to a homomorphism

$$

 x: A \to  C
$$
    
 And here's what I said: x_{i} converges to x precisely when the sequence
 of numbers x_{i}(a) converges to the number x(a) for all a in A.
 [Experts will know that now I'm lying slightly.  In general, to specify
 the topology of a space, it's not really good enough to just say when 
 \emph{sequences} converge; you need to say when \emph{nets} converge.  A net is 
 like a sequence, but the index i can range over an arbitrary "directed 
 set".  I don't feel like defining a directed set right now; one can
 find this in any good introduction to point-set topology.  The point is
 that there are some spaces that are not "first countable", meaning that
 some points don't have a countable base of neighborhoods.  A countable 
 sequence just isn't \emph{long} enough to converge to such a point, unless it
 equals that point for all sufficiently large i.  So in general we need
 nets, though for metric spaces sequences are sufficient.  Luckily, the 
 notation and basic theorems concerning nets look almost like those for 
 sequences!  So, I was actually talking about nets in my post above - but 
 I was hoping that people who only knew about sequences would think I was 
 talking about sequences, in which case they'd be \emph{slightly} wrong, but not 
 too far off.]

Squark wrote:
\begin{quote}



% parser failed at source line 762
